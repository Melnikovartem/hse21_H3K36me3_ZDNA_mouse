{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network_hw2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkVPIZTuxPJL",
        "outputId": "63d84e3e-1147-493f-890b-6626e526ad7c"
      },
      "source": [
        "# делаю в colab, так что надо скачать из репозитория данные\n",
        "!wget -O mm10_pos.fa https://raw.githubusercontent.com/Melnikovartem/hse21_H3K36me3_ZDNA_mouse/master/data/mm10_pos.fa\n",
        "!wget -O mm10_neg.fa https://raw.githubusercontent.com/Melnikovartem/hse21_H3K36me3_ZDNA_mouse/master/data/mm10_neg.fa"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 15:52:52--  https://raw.githubusercontent.com/Melnikovartem/hse21_H3K36me3_ZDNA_mouse/master/data/mm10_pos.fa\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167243 (163K) [text/plain]\n",
            "Saving to: ‘mm10_pos.fa’\n",
            "\n",
            "\rmm10_pos.fa           0%[                    ]       0  --.-KB/s               \rmm10_pos.fa         100%[===================>] 163.32K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-01 15:52:52 (7.06 MB/s) - ‘mm10_pos.fa’ saved [167243/167243]\n",
            "\n",
            "--2021-12-01 15:52:52--  https://raw.githubusercontent.com/Melnikovartem/hse21_H3K36me3_ZDNA_mouse/master/data/mm10_neg.fa\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167224 (163K) [text/plain]\n",
            "Saving to: ‘mm10_neg.fa’\n",
            "\n",
            "mm10_neg.fa         100%[===================>] 163.30K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-01 15:52:52 (7.18 MB/s) - ‘mm10_neg.fa’ saved [167224/167224]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2GC6enEV_Le",
        "outputId": "ea8aee8a-35b5-47d1-9da3-1495d676406c"
      },
      "source": [
        "__author__ = 'jasperz'\n",
        "# This code was created with\n",
        "# python 3.5\n",
        "# tensorflow 1.7\n",
        "# cuda 9.0\n",
        "# cudnn 7.0\n",
        "\n",
        "\n",
        "import os\n",
        "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "\n",
        "\n",
        "# An object of this class represents a neural network, which you can build, print, train, evaluate, save and load.\n",
        "# Below, the functions are discussed in detail.\n",
        "\n",
        "class NetworkModel:\n",
        "    tf.disable_v2_behavior()\n",
        "    # The constructor for the NetworkModel class comes with one optional argument. If no filename is given in input,\n",
        "    # it just creates a new, empty neural network model from scratch. If a filename is given, it loads a model that was\n",
        "    # previously saved to that file using the saveModel(...) function. Note that loaded files can only be used for\n",
        "    # evaluation, and not for (re)training or adding extra layers.\n",
        "    def __init__(self, file_to_load = None):\n",
        "        tf.reset_default_graph()\n",
        "        self.all_layers = []\n",
        "\n",
        "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
        "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
        "        config.gpu_options.allow_growth = True\n",
        "\n",
        "        self.sess = tf.Session(config=config)\n",
        "\n",
        "        if not file_to_load:\n",
        "            self.X_placeholder = tf.placeholder(tf.float32, [None, BLOCK_SIZE, 4],name='X_placeholder')\n",
        "            self.Y_placeholder = tf.placeholder(tf.float32, [None, 2],name='Y_placeholder')\n",
        "            self.loaded = False\n",
        "            self.nn = None\n",
        "        else:\n",
        "            self.loaded = True\n",
        "            self._loadNetworkParameters('models/'+file_to_load)\n",
        "            self.X_placeholder = tf.get_default_graph().get_tensor_by_name('X_placeholder:0')\n",
        "            self.Y_placeholder = tf.get_default_graph().get_tensor_by_name('Y_placeholder:0')\n",
        "            self.predictions_softmax = tf.get_default_graph().get_tensor_by_name('softmax_prediction:0')\n",
        "\n",
        "    # This function adds an input layer to the network. This is the first layer that should be added to every network\n",
        "    # model.\n",
        "    def addInputLayer(self):\n",
        "        assert len(self.all_layers) == 0, 'The input layer should be the first layer of the network, and can only be added once.'\n",
        "        self.all_layers.append(('Input layer','',self.X_placeholder))\n",
        "\n",
        "    # This function adds a convolutional layer to the network, with the specified arguments. You should always specify\n",
        "    # the number of filters (with an upper limit of 500), and the filter width (with an upper limit of 64). There is\n",
        "    # also an optional argument which lets you choose whether or not zero padding is added (as explained in the lecture\n",
        "    # slides). After each convolutional layer, a rectified linear unit (ReLU) is automatically added for\n",
        "    # non-linearization purposes.\n",
        "    def addConvLayer(self, num_of_filters, filter_width, zero_padding = True):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert zero_padding in (True,False), 'zero_padding should be True or False (boolean)'\n",
        "        assert 0 < num_of_filters < 500, 'The number of filters specified should be a positive number, smaller than 500'\n",
        "        assert 0 < filter_width < 64, 'The width of your filters should be a positive number, smaller than 64'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        assert 'Fully-connected layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a convolutional layer after a fully-connected layer'\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a convolutional layer after a softmax layer'\n",
        "        prev_width = self.all_layers[-1][-1].shape[1]\n",
        "        assert zero_padding or prev_width >= filter_width, 'You cannot add a (non-zeropadded) convolution of width {} when the previous layer has an output width of {}'.format(filter_width,prev_width)\n",
        "        self.all_layers.append(('Convolutional layer',\n",
        "                                '{} filters, width {}, {}zero padding, with ReLU'.format(num_of_filters,\n",
        "                                                                                         filter_width,\n",
        "                                                                                         'no ' if not zero_padding else ''),\n",
        "                                tf.layers.conv1d(self.all_layers[-1][-1],\n",
        "                                                 filters=num_of_filters,\n",
        "                                                 kernel_size=filter_width,\n",
        "                                                 activation=tf.nn.relu,\n",
        "                                                 padding='same' if zero_padding else 'valid')))\n",
        "\n",
        "    # This function adds a max pooling layer to the network, with the specified pool size (with an upper limit of 50).\n",
        "    def addMaxPoolLayer(self, pool_size):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert 'Fully-connected layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a pooling layer after a fully-connected layer'\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a pooling layer after a softmax layer'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        assert 0 < pool_size < 50, 'The pool size should be lower than 50'\n",
        "        prev_width = self.all_layers[-1][-1].shape[1]\n",
        "        assert prev_width >= pool_size, 'You cannot add a pooling layer with pool size {} when the previous layer has an output width of {}'.format(pool_size,prev_width)\n",
        "        self.all_layers.append(('Max pooling layer',\n",
        "                                'pool size {}'.format(pool_size),\n",
        "                                tf.layers.max_pooling1d(self.all_layers[-1][-1],\n",
        "                                                        pool_size=pool_size,\n",
        "                                                        strides=pool_size)))\n",
        "    # This function adds a fully-connected layer to the network, with the specified number of neurons (with an upper\n",
        "    # limit of 1000). If it is the first fully-connected layer in the network, it will also add a flatten layer first,\n",
        "    # which reduces the dimensionality after the convolutional/pooling layers. For instance, if the output of the last\n",
        "    # pooling layer is (?, 20, 100), the flatten layer will change this to (?, 2000). It is also no longer possible to\n",
        "    # add convolutional or pooling layers after this. After each fully-connected layer, a rectified linear unit (ReLU)\n",
        "    # is automatically added for non-linearization purposes.\n",
        "    def addFullyConnectedLayer(self,num_of_neurons):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a fully-connected layer after a softmax layer'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        assert 0 < num_of_neurons < 1000, 'The amount of neurons in this layer should be a positive number, lower than 2000'\n",
        "        if len(self.all_layers[-1][-1].shape) > 2:\n",
        "            self.all_layers.append(('Flatten layer',\n",
        "                                    '',\n",
        "                                   tf.layers.flatten(self.all_layers[-1][-1])))\n",
        "        self.all_layers.append(('Fully-connected layer',\n",
        "                                '{} neurons, with ReLU'.format(num_of_neurons),\n",
        "                                tf.layers.dense(self.all_layers[-1][-1],num_of_neurons)))\n",
        "\n",
        "    # This function adds an output layer to the network, which has two neurons: one for negative classification and one\n",
        "    # for positive classification. A softmax calculation is also done, so that the probabilities that are outputted by\n",
        "    # both neurons add up to 1. Once an output layer is added, no other layers can be added anymore.\n",
        "    def addOutputLayer(self):\n",
        "        assert len(self.all_layers) > 0 and self.all_layers[0][0].startswith('Input layer')\n",
        "        assert 'Softmax (output) layer' not in [typ for typ,_,_ in self.all_layers], 'You cannot add a softmax (output) layer after a softmax layer'\n",
        "        assert len(self.all_layers)+1 < 21, 'The total amount of layers should be at most 20'\n",
        "        if len(self.all_layers[-1][-1].shape) > 2:\n",
        "            self.all_layers.append(('Flatten layer',\n",
        "                                    '',\n",
        "                                    tf.contrib.layers.flatten(self.all_layers[-1][-1])))\n",
        "        # assert no output layer yet\n",
        "        # assert # of layers\n",
        "        self.all_layers.append(('Softmax (output) layer',\n",
        "                                '2 neurons',\n",
        "                                tf.layers.dense(self.all_layers[-1][-1], 2,name='logits')))\n",
        "    # You can use this function for printing out an overview of the layers that you have added to the network. It can\n",
        "    # be not only be used for a completed network, but also intermediately, for a network that is still being built.\n",
        "    # The output is printed out, and will consist of three columns: the type of layer, the hyperparameters (such as the\n",
        "    # number of neurons) and the output size after this layer. This output size will be shown in a format (?, BLOCK_SIZE, 100).\n",
        "    # The question mark indicates the amount of input samples (which is not fixed), so in building your network you can\n",
        "    # ignore this.\n",
        "    def printDetails(self):\n",
        "        print('####################################')\n",
        "        print('Network information:')\n",
        "        # count all parameters:\n",
        "        total_parameters = 0\n",
        "        # iterating over all variables\n",
        "        for variable in tf.trainable_variables():\n",
        "            local_parameters = 1\n",
        "            shape = variable.get_shape()  # getting shape of a variable\n",
        "            for i in shape:\n",
        "                local_parameters *= i.value  # mutiplying dimension values\n",
        "            total_parameters += local_parameters\n",
        "        print('This network has {} trainable parameters.'.format(total_parameters))\n",
        "\n",
        "        for i,(name,info,l) in enumerate(self.all_layers):\n",
        "            try:\n",
        "                print('{: >2d}. {:23} {:50} -> Output size: {}'.format(i, name, info, l.shape))\n",
        "            except AttributeError:\n",
        "                pass\n",
        "        print('')\n",
        "        print('####################################')\n",
        "\n",
        "\n",
        "    # To train the network, you will first need to read in the datasets, and convert the sequences to the right format.\n",
        "    # More in this format will follow in the assignments. After supplying the training and validation sets, you need to\n",
        "    # specify for how many epochs you want to train (maximum 100). The training and validation costes and accuracies\n",
        "    # will be shown on the screen.\n",
        "    def train(self, trainX, trainY, validX, validY, n_epochs):\n",
        "        print('####################################')\n",
        "        assert 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot train a model without an input layer'\n",
        "        assert 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot train a model without an output layer'\n",
        "        assert self.loaded == False, 'You can not (re)train a model loaded from a file.'\n",
        "        assert 1 < n_epochs < 100, 'The number of epochs should be greater than 1 and lower than 100'\n",
        "        assert all(type(l) == list for l in (trainX, trainY, validX, validY)), 'trainX, trainY, validX and validY should all be lists'\n",
        "        assert all(len(l) > 0 for l in (trainX, trainY, validX, validY)), 'trainX, trainY, validX and validY should not be empty'\n",
        "\n",
        "        assert len(trainX) == len(trainY), 'trainX and trainY should have the same amount of samples'\n",
        "        assert len(trainX[0]) == BLOCK_SIZE and len(trainX[0][0]) == 4 and type(trainX[0][0][0]) == int, 'trainX should have size (_, BLOCK_SIZE, 4) and should contain integers'\n",
        "        assert type(trainY[0]) == int, 'trainY should have length n (for n sequences) and should contain integers'\n",
        "\n",
        "        assert len(validX) == len(validY), 'validX and validY should have the same amount of samples'\n",
        "        assert len(validX[0]) == BLOCK_SIZE and len(validX[0][0]) == 4 and type(validX[0][0][0]) == int, 'validX should have size (_, BLOCK_SIZE, 4) and should contain integers'\n",
        "        assert type(validY[0]) == int, 'validY should have length n (for n sequences) and should contain integers'\n",
        "        # assert input and output layer\n",
        "        self._prepare_training()\n",
        "\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        self.sess.run(tf.local_variables_initializer())\n",
        "        train_dataset = _Dataset(trainX, trainY)\n",
        "        valid_dataset = _Dataset(validX, validY)\n",
        "        self._printOutputClasses(train_dataset,'training')\n",
        "        self._printOutputClasses(valid_dataset,'validation')\n",
        "\n",
        "        best_valid_score = 999999\n",
        "        print()\n",
        "        print(' {:^5} | {:^14} | {:^14} | {:^11} | {:^11} | {:^8} '.format('epoch','train cost','valid cost','train acc','valid acc','time'))\n",
        "        print('-{:-^6}+{:-^16}+{:-^16}+{:-^13}+{:-^13}+{:-^9}-'.format('','','','','',''))\n",
        "\n",
        "        tr_cost, tr_acc = self._evaluateSet(train_dataset)\n",
        "        va_cost, va_acc = self._evaluateSet(valid_dataset)\n",
        "        print(' {:5d} |   {:2.8f}   |   {:2.8f}   |  {:1.7f}  | {:1.7f}  | {:4.2f}s '.format(0,tr_cost,tr_acc,va_cost,va_acc,0))\n",
        "\n",
        "        for epoch in range(1,n_epochs+1):\n",
        "            epoch_start_time = time.time()\n",
        "            epoch_finished = False\n",
        "            while not epoch_finished:\n",
        "                batch_x, batch_y, epoch_finished = train_dataset.next_batch(256)\n",
        "                self.sess.run(self.train_op, feed_dict={self.X_placeholder: batch_x, self.Y_placeholder: batch_y})\n",
        "            tr_cost, tr_acc = self._evaluateSet(train_dataset)\n",
        "            va_cost, va_acc = self._evaluateSet(valid_dataset)\n",
        "\n",
        "            if va_cost < best_valid_score:\n",
        "                best_valid_score = va_cost\n",
        "                message = '-> model selected'\n",
        "                self._storeNetworkParameters('models/tmp')\n",
        "            else:\n",
        "                message = ''\n",
        "            print(' {:5d} |   {:2.8f}   |   {:2.8f}   |  {:1.7f}  | {:1.7f}  | {:4.2f}s {}'.format(epoch,tr_cost,va_cost,tr_acc,va_acc,time.time()-epoch_start_time,message))\n",
        "\n",
        "        self._loadNetworkParameters('models/tmp')\n",
        "        print('Finished training')\n",
        "        print('####################################')\n",
        "\n",
        "    # This is the function you will use to generate predictions for a certain dataset. In input, you give a list of\n",
        "    # sequences, in the one-hot encoding format (again, see the assignments). It will output a list of probabilities\n",
        "    # as calculated by the network. The list is a two-dimensional list of size (n, 2), with n being the number of\n",
        "    # sequences in testX. This means that the list will be a list will contain n lists of size 2, each containing the\n",
        "    # negative and positive probability for the prediction.\n",
        "    def generatePredictions(self, testX):\n",
        "        assert len(testX[0]) == BLOCK_SIZE and len(testX[0][0]) == 4 and type(testX[0][0][0]) == int, 'testX should have size (_, BLOCK_SIZE, 4) and should contain integers'\n",
        "        assert self.loaded or 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot test a model without an input layer'\n",
        "        assert self.loaded or 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot test a model without an output layer'\n",
        "        # assert input and output layer\n",
        "        all_preds = []\n",
        "        for i in range(math.ceil(len(testX)/256)):\n",
        "            batch_x = np.asarray(testX[i*256:(i+1)*256])\n",
        "            preds = self.sess.run(self.predictions_softmax,feed_dict={self.X_placeholder:batch_x})\n",
        "            for i in range(len(preds)):\n",
        "                all_preds.append((preds[i][0],preds[i][1]))\n",
        "        return all_preds\n",
        "\n",
        "    # At any time, you can save your current model (with its layers and trained parameters) to a file. However, it\n",
        "    # really only makes sense to do this after training. To load this model again, create a new NetworkModel object,\n",
        "    # and specify the same filename in the file_to_load parameter. Note: after loading a model, it cannot be\n",
        "    # (re)trained.\n",
        "    def saveModel(self, file_to_save_to):\n",
        "        assert 'Input layer' in [typ for typ,_,_ in self.all_layers], 'You cannot save a model without an input layer'\n",
        "        assert 'Softmax (output) layer' in [typ for typ,_,_ in self.all_layers], 'You cannot save a model without an output layer'\n",
        "        # assert input and output layer\n",
        "        assert not self.loaded, 'You cannot save a loaded model again.'\n",
        "        self._storeNetworkParameters('models/'+file_to_save_to)\n",
        "\n",
        "    def _prepare_training(self):\n",
        "        # assert all layers -1 == output layer\n",
        "        gs = tf.train.get_or_create_global_step()\n",
        "        self.predictions_softmax = tf.nn.softmax(self.all_layers[-1][-1],name='softmax_prediction')\n",
        "\n",
        "        self.cost_f = tf.losses.softmax_cross_entropy(onehot_labels=self.Y_placeholder, logits=self.all_layers[-1][-1])\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "        self.train_op = self.optimizer.minimize(loss=self.cost_f,global_step=gs)\n",
        "\n",
        "        self.acc_f, self.acc_op = tf.metrics.accuracy(labels=tf.argmax(self.Y_placeholder, axis=1),predictions=tf.argmax(self.predictions_softmax, axis=1),name='metric_acc')\n",
        "        self.metric_var_initializer = tf.variables_initializer(var_list=tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope='metric'))\n",
        "\n",
        "    def _evaluateSet(self, dataset):\n",
        "        self.sess.run(self.metric_var_initializer)\n",
        "        costs = []\n",
        "        batches_done = False\n",
        "        while not batches_done:\n",
        "            batch_x, batch_y, epoch_finished = dataset.next_batch(256)\n",
        "\n",
        "            cost_batch = self.sess.run(self.cost_f, feed_dict={self.X_placeholder: batch_x,self.Y_placeholder: batch_y})\n",
        "            _ = self.sess.run([self.acc_op], feed_dict={self.X_placeholder: batch_x,self.Y_placeholder: batch_y})\n",
        "            costs.extend([cost_batch] * len(batch_y))\n",
        "\n",
        "            if epoch_finished:\n",
        "                batches_done = True\n",
        "\n",
        "        accuracy = self.sess.run([self.acc_f])[0]\n",
        "        return np.average(costs),accuracy\n",
        "\n",
        "    def _printOutputClasses(self, dataset, label):\n",
        "        print()\n",
        "        counts = dataset.getClassCounts()\n",
        "        print('Number of {} examples: {}'.format(label,int(np.sum(counts))))\n",
        "        if len(counts) > 1:\n",
        "            print('Distribution of the {} set:'.format(label))\n",
        "            for i in range(min(10,len(counts))):\n",
        "                print('  # elements of class {} = {}'.format(i,int(counts[i])))\n",
        "\n",
        "    def _storeNetworkParameters(self, saveToDir):\n",
        "        try:\n",
        "            saver = tf.train.Saver()\n",
        "            if not os.path.exists(saveToDir):\n",
        "                os.makedirs(saveToDir)\n",
        "            saver.save(self.sess,saveToDir+'/'+saveToDir[saveToDir.rfind('/')+1:])\n",
        "        except Exception:\n",
        "            print('SOMETHING WENT WRONG WITH STORING SHIT JASPER!! ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "            print(sys.exc_info())\n",
        "            print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "\n",
        "    def _loadNetworkParameters(self, saveToDir):\n",
        "        filename = saveToDir+'/'+saveToDir[saveToDir.rfind('/')+1:]\n",
        "        if self.loaded:\n",
        "            saver = tf.train.import_meta_graph(filename+'.meta')\n",
        "        else:\n",
        "            saver = tf.train.Saver()\n",
        "        saver.restore(self.sess, tf.train.latest_checkpoint(saveToDir))\n",
        "\n",
        "\n",
        "class _Dataset:\n",
        "\n",
        "    def __init__(self,x_data,y_data=None):\n",
        "        if isinstance(x_data,list):\n",
        "            x_data = np.asarray(x_data)\n",
        "\n",
        "        self.index_in_epoch = 0\n",
        "        self.x_data = x_data\n",
        "        self.num_samples = x_data.shape[0]\n",
        "\n",
        "        if y_data:\n",
        "            if isinstance(y_data,list):\n",
        "                y_data = self._convertY(y_data)\n",
        "                self.y_data = y_data\n",
        "        else:\n",
        "            self.y_data = []\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def getClassCounts(self):\n",
        "        return np.sum(self.y_data,axis=0)\n",
        "\n",
        "    def _convertY(self, y_data):\n",
        "        out = np.zeros((len(y_data),2))\n",
        "        for i,cl in enumerate(y_data):\n",
        "            out[i][cl] = 1\n",
        "        return out\n",
        "\n",
        "    def next_batch(self,batch_size):\n",
        "        start = self.index_in_epoch\n",
        "        end = self.index_in_epoch + batch_size\n",
        "\n",
        "        if start == 0:\n",
        "            idx = np.arange(0, self.num_samples)  # get all possible indexes\n",
        "            np.random.shuffle(idx)  # shuffle indexes\n",
        "            self.x_data = self.x_data[idx]\n",
        "            if len(self.y_data) > 0:\n",
        "                self.y_data = self.y_data[idx]\n",
        "\n",
        "        if end < self.num_samples:\n",
        "            self.index_in_epoch = end\n",
        "            return self.x_data[start:end], self.y_data[start:end], False # epoch finished = False\n",
        "        else:\n",
        "            self.index_in_epoch = 0\n",
        "            return self.x_data[start:], self.y_data[start:], True #epoch finished = True\n",
        "\n",
        "\n",
        "    def stepsInEpoch(self,batch_size):\n",
        "        return math.ceil(len(self) / batch_size)\n",
        "\n",
        "    def getX(self):\n",
        "        return self.x_data\n",
        "\n",
        "    def getSequenceLength(self):\n",
        "        return len(self.x_data[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFwpPlrKxxyK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWj7Uz95oKaP"
      },
      "source": [
        "BLOCK_SIZE = 1000"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaDChprP4Us1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff37e68-0e7e-46c1-e63c-a9d73883cb4f"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "def add_file(name, target):\n",
        "  base = []\n",
        "  with open(name) as f:\n",
        "    for line in f.readlines():\n",
        "      if line[0] != \">\":\n",
        "        for c in line.strip():\n",
        "          cc = c.upper()\n",
        "          if cc == 'A':\n",
        "              v = [1,0,0,0]\n",
        "          elif cc == 'C':\n",
        "              v = [0,1,0,0]\n",
        "          elif cc == 'G':\n",
        "              v = [0,0,1,0]\n",
        "          elif cc == 'T':\n",
        "              v = [0,0,0,1]\n",
        "          elif cc == 'N':\n",
        "              v = [0,0,0,0]\n",
        "          else:\n",
        "              raise ValueError(\"Not Supported: \", cc)\n",
        "          base.append(v)\n",
        "          if len(base) == BLOCK_SIZE:\n",
        "              X.append(base)\n",
        "              y.append(target)\n",
        "              base = []\n",
        "    print(len(base))\n",
        "\n",
        "\n",
        "add_file(\"mm10_neg.fa\", 0)\n",
        "add_file(\"mm10_pos.fa\", 1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B7PqlR5WeLC"
      },
      "source": [
        "def myNetworkTF():\n",
        "  model = NetworkModel()\n",
        "  model.addInputLayer()\n",
        "  model.addFullyConnectedLayer(50)\n",
        "  model.addFullyConnectedLayer(50)\n",
        "  model.addOutputLayer()\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUQJStx-Rh3I"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.25)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size = 0.25)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW1e3SyhWeSr",
        "outputId": "2a27bf1d-1e86-4e7a-9c73-95a1391ec231"
      },
      "source": [
        "model = myNetworkTF()\n",
        "model.printDetails()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################\n",
            "Network information:\n",
            "This network has 202702 trainable parameters.\n",
            " 0. Input layer                                                                -> Output size: (?, 1000, 4)\n",
            " 1. Flatten layer                                                              -> Output size: (?, 4000)\n",
            " 2. Fully-connected layer   50 neurons, with ReLU                              -> Output size: (?, 50)\n",
            " 3. Fully-connected layer   50 neurons, with ReLU                              -> Output size: (?, 50)\n",
            " 4. Softmax (output) layer  2 neurons                                          -> Output size: (?, 2)\n",
            "\n",
            "####################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:523: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:130: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQAV4HZRWeVs",
        "outputId": "e00c6276-9b1a-41d7-894c-b92747a93803"
      },
      "source": [
        "model.train(X_train, y_train, X_valid, y_valid, 10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################\n",
            "\n",
            "Number of training examples: 20\n",
            "Distribution of the training set:\n",
            "  # elements of class 0 = 11\n",
            "  # elements of class 1 = 9\n",
            "\n",
            "Number of validation examples: 61\n",
            "Distribution of the validation set:\n",
            "  # elements of class 0 = 32\n",
            "  # elements of class 1 = 29\n",
            "\n",
            " epoch |   train cost   |   valid cost   |  train acc  |  valid acc  |   time   \n",
            "-------+----------------+----------------+-------------+-------------+----------\n",
            "     0 |   0.81626481   |   0.50000000   |  0.8348655  | 0.5737705  | 0.00s \n",
            "     1 |   0.71158344   |   1.94157577   |  0.7000000  | 0.5245901  | 0.18s -> model selected\n",
            "     2 |   0.01322964   |   0.70469928   |  1.0000000  | 0.6721311  | 0.14s -> model selected\n",
            "     3 |   0.01703661   |   0.86195207   |  1.0000000  | 0.5901639  | 0.01s \n",
            "     4 |   0.04938619   |   1.51136303   |  1.0000000  | 0.4918033  | 0.01s \n",
            "     5 |   0.04756380   |   1.90558779   |  1.0000000  | 0.4754098  | 0.01s \n",
            "     6 |   0.02106207   |   1.98413682   |  1.0000000  | 0.4754098  | 0.01s \n",
            "     7 |   0.00731497   |   1.92704070   |  1.0000000  | 0.4918033  | 0.02s \n",
            "     8 |   0.00260580   |   1.83374619   |  1.0000000  | 0.5081967  | 0.01s \n",
            "     9 |   0.00101943   |   1.73776078   |  1.0000000  | 0.5081967  | 0.01s \n",
            "    10 |   0.00044053   |   1.64925551   |  1.0000000  | 0.5081967  | 0.02s \n",
            "INFO:tensorflow:Restoring parameters from models/tmp/tmp\n",
            "Finished training\n",
            "####################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B461_AtgWeb-"
      },
      "source": [
        "pred = model.generatePredictions(X_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlSU-TFutAFi"
      },
      "source": [
        "def recall(preds,labs):\n",
        "    tp,tn,fn,fp = 0,0,0,0\n",
        "    for (_,p),l in zip(preds,labs):\n",
        "        if p >= .5 and l == 1:\n",
        "            tp += 1\n",
        "        elif p < .5 and l == 1:\n",
        "            fn += 1\n",
        "        elif p >= .5 and l == 0:\n",
        "            fp += 1\n",
        "        else:\n",
        "            tn += 1\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "def precision(preds,labs):\n",
        "    tp,tn,fn,fp = 0,0,0,0\n",
        "    for (_,p),l in zip(preds,labs):\n",
        "        if p >= .5 and l == 1:\n",
        "            tp += 1\n",
        "        elif p < .5 and l == 1:\n",
        "            fn += 1\n",
        "        elif p >= .5 and l == 0:\n",
        "            fp += 1\n",
        "        else:\n",
        "            tn += 1\n",
        "    return tp / (tp + fp)\n",
        "\n",
        "def f1(preds,labs):\n",
        "    r,p = recall(preds,labs), precision(preds,labs)\n",
        "    return 2 * r * p / (r + p)\n",
        "def f1(preds,labs):\n",
        "    r,p = recall(preds,labs), precision(preds,labs)\n",
        "    return 2 * r * p / (r + p)\n",
        "def fbeta(preds,labs,beta = 1):\n",
        "    beta_2 = beta ** 2\n",
        "    r,p = recall(preds,labs), precision(preds,labs)\n",
        "    return (1 + beta_2) * r * p / (r + p * beta_2)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYk9dsIDtA91",
        "outputId": "ee85a59e-b2c9-48bd-c7b4-3efd125879ed"
      },
      "source": [
        "recall(pred, y_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvxq1awLtm3_",
        "outputId": "c34f35d1-bc93-469f-b554-15bf33c2eb47"
      },
      "source": [
        "precision(pred, y_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7352941176470589"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbXrK-SSuaBX",
        "outputId": "2254c9b5-ef86-474b-a31c-fd2b42a846d1"
      },
      "source": [
        "fbeta(pred, y_test, 0.5)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6297229219143576"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQqC550IukcU"
      },
      "source": [
        "def networkTestCycle(myNetwork):\n",
        "  model = myNetwork()\n",
        "  model.train(X_train, y_train, X_valid, y_valid, 50)\n",
        "  pred = model.generatePredictions(X_test)\n",
        "  return model,fbeta(pred, y_test, 0.2)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Bx157CvBCN"
      },
      "source": [
        "def myNetworkCNN():\n",
        "  model = NetworkModel()\n",
        "  model.addInputLayer()\n",
        "  model.addConvLayer(25, 10)\n",
        "  model.addMaxPoolLayer(5)\n",
        "  model.addConvLayer(10, 15)\n",
        "  model.addMaxPoolLayer(2)\n",
        "  model.addConvLayer(5, 10)\n",
        "  model.addFullyConnectedLayer(10)\n",
        "  model.addFullyConnectedLayer(10)\n",
        "  model.addOutputLayer()\n",
        "  return model"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7bHYXHou_LZ",
        "outputId": "3c4001e9-063f-4f4a-9838-383648ba4244"
      },
      "source": [
        "model, criterion = networkTestCycle(myNetworkCNN)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:80: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:288: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: UserWarning: `tf.layers.max_pooling1d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling1D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/pooling.py:294: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:523: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:130: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################################\n",
            "\n",
            "Number of training examples: 20\n",
            "Distribution of the training set:\n",
            "  # elements of class 0 = 11\n",
            "  # elements of class 1 = 9\n",
            "\n",
            "Number of validation examples: 61\n",
            "Distribution of the validation set:\n",
            "  # elements of class 0 = 32\n",
            "  # elements of class 1 = 29\n",
            "\n",
            " epoch |   train cost   |   valid cost   |  train acc  |  valid acc  |   time   \n",
            "-------+----------------+----------------+-------------+-------------+----------\n",
            "     0 |   0.72714454   |   0.44999999   |  0.7010540  | 0.4918033  | 0.00s \n",
            "     1 |   0.69412404   |   0.69602728   |  0.4500000  | 0.4590164  | 0.26s -> model selected\n",
            "     2 |   0.67448509   |   0.69309002   |  0.6500000  | 0.4590164  | 0.14s -> model selected\n",
            "     3 |   0.65627873   |   0.68763220   |  0.7500000  | 0.5245901  | 0.15s -> model selected\n",
            "     4 |   0.63425815   |   0.68174076   |  0.9000000  | 0.5573770  | 0.15s -> model selected\n",
            "     5 |   0.60519993   |   0.67497134   |  0.9000000  | 0.5573770  | 0.16s -> model selected\n",
            "     6 |   0.57245243   |   0.66745794   |  0.9000000  | 0.5573770  | 0.16s -> model selected\n",
            "     7 |   0.53790504   |   0.65688193   |  0.9000000  | 0.5901639  | 0.17s -> model selected\n",
            "     8 |   0.49819502   |   0.63987005   |  0.9000000  | 0.6229508  | 0.17s -> model selected\n",
            "     9 |   0.45126009   |   0.61508012   |  0.9000000  | 0.7049180  | 0.18s -> model selected\n",
            "    10 |   0.40228161   |   0.58340538   |  0.9000000  | 0.7377049  | 0.17s -> model selected\n",
            "    11 |   0.35681233   |   0.55153227   |  0.8500000  | 0.7540984  | 0.20s -> model selected\n",
            "    12 |   0.30748469   |   0.52299666   |  0.9000000  | 0.7704918  | 0.21s -> model selected\n",
            "    13 |   0.25771341   |   0.50687253   |  0.9500000  | 0.7704918  | 0.22s -> model selected\n",
            "    14 |   0.21323386   |   0.49510196   |  0.9500000  | 0.7704918  | 0.20s -> model selected\n",
            "    15 |   0.17101905   |   0.46430650   |  0.9500000  | 0.8032787  | 0.20s -> model selected\n",
            "    16 |   0.13786432   |   0.44793960   |  0.9500000  | 0.8032787  | 0.20s -> model selected\n",
            "    17 |   0.10521098   |   0.43234038   |  1.0000000  | 0.8360656  | 0.22s -> model selected\n",
            "    18 |   0.08137047   |   0.41911718   |  1.0000000  | 0.8196721  | 0.23s -> model selected\n",
            "    19 |   0.05950999   |   0.40213907   |  1.0000000  | 0.8688524  | 0.21s -> model selected\n",
            "    20 |   0.04502143   |   0.40386388   |  1.0000000  | 0.8688524  | 0.03s \n",
            "    21 |   0.03168718   |   0.40219375   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    22 |   0.02242335   |   0.40563563   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    23 |   0.01540955   |   0.41796768   |  1.0000000  | 0.8852459  | 0.03s \n",
            "    24 |   0.00998257   |   0.43572345   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    25 |   0.00668725   |   0.45931181   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    26 |   0.00461750   |   0.48318970   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    27 |   0.00312901   |   0.50284803   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    28 |   0.00208355   |   0.51932383   |  1.0000000  | 0.8852459  | 0.03s \n",
            "    29 |   0.00141076   |   0.53459597   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    30 |   0.00099764   |   0.54992670   |  1.0000000  | 0.8688524  | 0.03s \n",
            "    31 |   0.00073707   |   0.56542540   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    32 |   0.00056393   |   0.58082259   |  1.0000000  | 0.8524590  | 0.02s \n",
            "    33 |   0.00043934   |   0.59574372   |  1.0000000  | 0.8524590  | 0.02s \n",
            "    34 |   0.00034404   |   0.60990900   |  1.0000000  | 0.8524590  | 0.02s \n",
            "    35 |   0.00026952   |   0.62325162   |  1.0000000  | 0.8524590  | 0.02s \n",
            "    36 |   0.00021152   |   0.63579446   |  1.0000000  | 0.8524590  | 0.02s \n",
            "    37 |   0.00016687   |   0.64760232   |  1.0000000  | 0.8524590  | 0.03s \n",
            "    38 |   0.00013291   |   0.65879726   |  1.0000000  | 0.8524590  | 0.02s \n",
            "    39 |   0.00010737   |   0.66941512   |  1.0000000  | 0.8688524  | 0.03s \n",
            "    40 |   0.00008823   |   0.67950273   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    41 |   0.00007387   |   0.68908441   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    42 |   0.00006299   |   0.69814444   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    43 |   0.00005464   |   0.70667553   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    44 |   0.00004815   |   0.71467972   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    45 |   0.00004300   |   0.72213912   |  1.0000000  | 0.8688524  | 0.03s \n",
            "    46 |   0.00003891   |   0.72904289   |  1.0000000  | 0.8688524  | 0.03s \n",
            "    47 |   0.00003556   |   0.73540473   |  1.0000000  | 0.8688524  | 0.02s \n",
            "    48 |   0.00003280   |   0.74121988   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    49 |   0.00003046   |   0.74651241   |  1.0000000  | 0.8852459  | 0.02s \n",
            "    50 |   0.00002848   |   0.75130904   |  1.0000000  | 0.8852459  | 0.02s \n",
            "INFO:tensorflow:Restoring parameters from models/tmp/tmp\n",
            "Finished training\n",
            "####################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirOKIodwOFz",
        "outputId": "b630b69e-c64f-4aec-b983-a57680e0f654"
      },
      "source": [
        "criterion"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166101694915255"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlom00OpWAHE"
      },
      "source": [
        "Ниже были мои попытки в **pyTorch**. Мб там есть ряд проблем (вроде не родной ROC-AUC), которые можно было бы решить, но зачем, когда есть неплохое готове решение на TF (которая потенциально более быстрая библиотека)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5KP1i7DRaLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "9e4fc983-44e3-410c-ca79-935090b19095"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "import torch\n",
        "import random\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoL8yJ6bxztP"
      },
      "source": [
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4VDA-8uR9VD"
      },
      "source": [
        "SEED = 42\n",
        "BATCH_SIZE = 512\n",
        "IN_FEATURES = 5"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug-_F8ysRUOd"
      },
      "source": [
        "set_random_seed(SEED)\n",
        "train_set = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, worker_init_fn = lambda x: set_random_seed(SEED))\n",
        "\n",
        "test_set = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
        "test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, worker_init_fn = lambda x: set_random_seed(SEED))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgg-ywIkQ7Vf"
      },
      "source": [
        "def train(model, optimizer, criterion, train_loader, test_loader):\n",
        "    '''\n",
        "    params:\n",
        "        model - torch.nn.Module to be fitted\n",
        "        optimizer - model optimizer\n",
        "        criterion - loss function from torch.nn\n",
        "        train_loader - torch.utils.data.Dataloader with train set\n",
        "        test_loader - torch.utils.data.Dataloader with test set\n",
        "                      (if you wish to validate during training)\n",
        "    '''\n",
        "    \n",
        "    model.train()\n",
        "    losses_epoch = {\n",
        "        \"max\": [],\n",
        "        \"mean\": [],\n",
        "        \"min\": [],\n",
        "        \"test\": [],\n",
        "    }\n",
        "\n",
        "    epoch_num = 5\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "      losses_rmse = []\n",
        "      for idx, (X, y) in enumerate(tqdm(train_loader, desc = f\"epoch {epoch}\")):\n",
        "          preds = model(X)\n",
        "          preds_val = model\n",
        "\n",
        "          loss = criterion(preds[:, 0], y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          losses_rmse.append(loss.item()**0.5 * yscaler.scale_[0])\n",
        "      \n",
        "      losses_epoch[\"test\"].append(mean_squared_error(y_test_scaled, test(model, criterion, test_loader))**0.5 * yscaler.scale_[0]);\n",
        "      losses_rmse = np.array(losses_rmse)\n",
        "      losses_epoch[\"max\"].append(losses_rmse.max()) \n",
        "      losses_epoch[\"mean\"].append(losses_rmse.mean())\n",
        "      losses_epoch[\"min\"].append(losses_rmse.min())\n",
        "\n",
        "      if (epoch % 2 == 0 or epoch == epoch_num - 1):\n",
        "        clear_output()\n",
        "        plt.plot(range(epoch + 1), losses_epoch[\"max\"], label = \"max\")\n",
        "        plt.plot(range(epoch + 1), losses_epoch[\"mean\"], label = \"mean\")\n",
        "        plt.plot(range(epoch + 1), losses_epoch[\"min\"], label = \"min\")\n",
        "        plt.plot(range(epoch + 1), losses_epoch[\"test\"], label = \"test\")\n",
        "        plt.xlabel(\"epoch _n\")\n",
        "        plt.ylabel(\"rmse natural\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        pad = max(len(losses_epoch) - 4, 0)\n",
        "        for i in range(pad, epoch + 1):\n",
        "          print(f'epoch: {i}, RMSE: test {\\\n",
        "                  losses_epoch[\"test\"][i]} mean {\\\n",
        "                  losses_epoch[\"mean\"][i] },  min {\\\n",
        "                  losses_epoch[\"min\"][i] }, max {\\\n",
        "                  losses_epoch[\"max\"][i] }');\n",
        "\n",
        "def test(model, criterion, test_loader):\n",
        "    '''\n",
        "    params:\n",
        "        model - torch.nn.Module to be evaluated on test set\n",
        "        criterion - loss function from torch.nn\n",
        "        test_loader - torch.utils.data.Dataloader with test set\n",
        "    ----------\n",
        "    returns:\n",
        "        predicts - torch.tensor with shape (len(test_loader.dataset), ),\n",
        "                   which contains predictions for test objects\n",
        "    '''\n",
        "    predicts = torch.ones(len(test_loader.dataset))\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, (X, y) in enumerate(test_loader):\n",
        "            preds = model(X)\n",
        "            for jdx, pred in enumerate(preds):\n",
        "                predicts[idx * BATCH_SIZE + jdx] = pred\n",
        "    return predicts"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clysO3pNSb6X"
      },
      "source": [
        "class MyNetwork(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyNetwork, self).__init__()\n",
        "        self.net = nn.Sequential(    \n",
        "            nn.Linear(IN_FEATURES, 25),\n",
        "            nn.Dropout(0.7),\n",
        "            nn.BatchNorm1d(25),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Softmax(2)\n",
        "        )\n",
        "        self.net.apply(self.weigths)\n",
        "\n",
        "    def weigths(self, layer):\n",
        "      if isinstance(layer, nn.Linear):\n",
        "          torch.nn.init.xavier_uniform_(layer.weight)\n",
        "          layer.bias.data.fill_(0.01)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 81,
      "outputs": []
    }
  ]
}